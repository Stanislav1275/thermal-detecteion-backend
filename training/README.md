# Обучение модели детекции людей на термальных данных

## Обзор

Модель YOLOv8n обучается на датасете FLIR ADAS для детекции людей на тепловизионных изображениях. Процесс включает подготовку датасета, обучение модели и валидацию результатов.

## Структура датасета

После подготовки датасет имеет следующую структуру:

```
datasets/yolo/
├── train/
│   ├── images/          # Обучающие изображения
│   └── labels/          # Метки в формате YOLO
└── val/
    ├── images/          # Валидационные изображения
    └── labels/          # Метки в формате YOLO
```

## Формат меток YOLO

Каждый файл меток содержит строки в формате:
```
class_id center_x center_y width height
```

Все координаты нормализованы относительно размера изображения (0.0 - 1.0).

Классы:
- 0: person
- 1: car

## Этап 1: Подготовка датасета

### Загрузка FLIR ADAS датасета

```bash
# Установка kagglehub (если еще не установлен)
pip install kagglehub

# Загрузка датасета
python -c "import kagglehub; print(kagglehub.dataset_download('deepnewbie/flir-thermal-images-dataset'))"
```

Датасет будет загружен в `~/.cache/kagglehub/datasets/deepnewbie/flir-thermal-images-dataset/versions/1/`

### Конвертация в YOLO формат

Скрипт `prepare_dataset.py` конвертирует аннотации из COCO JSON формата в YOLO формат.

```bash
python prepare_dataset.py \
    --dataset-root ~/.cache/kagglehub/datasets/deepnewbie/flir-thermal-images-dataset/versions/1 \
    --output-root ./datasets/yolo \
    --splits train val
```

Процесс конвертации:
1. Чтение COCO JSON аннотаций
2. Фильтрация только классов "person" и "car"
3. Конвертация координат из абсолютных в нормализованные (YOLO формат)
4. Копирование изображений в соответствующую структуру
5. Создание файлов меток (.txt) для каждого изображения

## Этап 2: Обучение модели

### Параметры обучения

```bash
python train.py \
    --data thermal.yaml \
    --model n \
    --epochs 100 \
    --batch 16 \
    --imgsz 640
```

Параметры:
- `--data`: Путь к YAML конфигурации датасета
- `--model`: Размер модели (n=nano, s=small, m=medium, l=large, x=xlarge)
- `--epochs`: Количество эпох обучения
- `--batch`: Размер батча
- `--imgsz`: Размер изображений для обучения (640x640)
- `--device`: Устройство (cpu, mps, cuda) или автоопределение

### Процесс обучения

1. Загрузка предобученной модели YOLOv8n
2. Определение устройства (MPS для Apple Silicon, CUDA для NVIDIA, CPU иначе)
3. Загрузка и подготовка данных из `thermal.yaml`
4. Обучение с аугментацией, оптимизированной для термальных данных
5. Валидация после каждой эпохи
6. Сохранение лучшей модели по метрике mAP@50
7. Автоматическое копирование лучшей модели в `training/models/best.pt`

### Аугментация

Аугментация настроена специально для термальных данных:
- Небольшое вращение (degrees: 5)
- Масштабирование ±20%
- Небольшой сдвиг (shear: 1)
- Без изменения оттенка (термальные данные)
- Небольшое изменение яркости (hsv_v: 0.1)
- Mosaic и Mixup аугментация

### Результаты обучения

Результаты сохраняются в `training/runs/detect/thermal_detection/`:
- `weights/best.pt` - лучшая модель
- `weights/last.pt` - последняя модель
- Графики метрик (loss, mAP, precision, recall)
- Confusion matrix
- Примеры предсказаний

Лучшая модель автоматически копируется в `training/models/best.pt`

## Этап 3: Валидация модели

### Запуск валидации

```bash
python validate.py \
    --model training/models/best.pt \
    --data thermal.yaml \
    --output training/results \
    --conf 0.25 \
    --visualize
```

### Процесс валидации

1. Загрузка обученной модели
2. Запуск валидации на тестовом наборе
3. Вычисление метрик качества:
   - mAP@50: средняя точность при IoU=0.5
   - mAP@50-95: средняя точность при IoU=0.5-0.95
   - Precision: точность детекций
   - Recall: полнота детекций
4. Сохранение метрик в JSON формате
5. Генерация графиков метрик
6. Визуализация предсказаний (если указан флаг --visualize)

### Результаты валидации

Создаются следующие файлы:
- `training/results/metrics.json` - метрики качества в JSON формате
- `training/results/visualizations/` - визуализации предсказаний (если --visualize)
- Графики метрик в `training/results/`

### Ожидаемые метрики

После обучения на FLIR ADAS датасете ожидаемые метрики:
- mAP@50: ≥ 0.70
- Precision: ≥ 0.75
- Recall: ≥ 0.70

## Технические детали

### Устройства для обучения

- **MPS (Metal Performance Shaders)**: Используется автоматически на Apple Silicon (M1/M2/M3/M4)
- **CUDA**: Используется автоматически при наличии NVIDIA GPU
- **CPU**: Используется по умолчанию, если GPU недоступен

### Время обучения

- CPU: ~6-8 часов для 100 эпох
- MPS (Apple Silicon): ~2-3 часа для 100 эпох
- CUDA (NVIDIA GPU): ~30-60 минут для 100 эпох

### Требования к памяти

- Минимум: 8 GB RAM
- Рекомендуется: 16 GB RAM
- Размер датасета: ~15 GB
- Размер модели: ~6 MB (YOLOv8n)

## Устранение неполадок

### Ошибка: "Модель не найдена"

Убедитесь, что обучение завершено и модель сохранена в `training/models/best.pt`

### Ошибка: "Датасет не найден"

Проверьте, что датасет подготовлен и находится в `training/datasets/yolo/`

### Низкие метрики

- Увеличьте количество эпох обучения
- Проверьте качество аннотаций в датасете
- Попробуйте другую модель (s, m, l вместо n)
